{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count  hate_speech_count  offensive_language_count  neither_count  class  \\\n",
      "0      3                  0                         0              3      2   \n",
      "1      3                  0                         3              0      1   \n",
      "2      3                  0                         3              0      1   \n",
      "3      3                  0                         2              1      1   \n",
      "4      6                  0                         6              0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kaca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kaca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kaca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preuzimanje potrebnih NLTK resursa\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prikaz distribucije podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Kreiraj novu kolonu 'label' za binarnu klasifikaciju\n",
    "df['label'] = df['class'].apply(lambda x: 1 if x == 1 else 0)\n",
    "def plot_distribution(data, column):\n",
    "# Prikaži distribuciju klasa\n",
    "    class_counts = data[column].value_counts()\n",
    "    sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "    plt.title('Distribucija klasa')\n",
    "    plt.xlabel('Klasa (0 = Nije govor mržnje, 1 = Govor mržnje)')\n",
    "    plt.ylabel('Broj primera')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tweet', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(df, 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesiranje teksta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, text_column):\n",
    "    \"\"\"\n",
    "    Funkcija za predobradu teksta.\n",
    "    \n",
    "    Argumenti:\n",
    "    - df: Pandas DataFrame koji sadrži kolonu sa tekstom.\n",
    "    - text_column: Ime kolone koja sadrži tekstualne podatke.\n",
    "    \n",
    "    Vraća:\n",
    "    - df: Pandas DataFrame sa novom kolonom 'clean_text' koja sadrži predobrađen tekst.\n",
    "    \"\"\"\n",
    "    # Kopiramo originalni DataFrame da ne bismo menjali originalne podatke\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Uklanjanje URL-ova i email adresa\n",
    "    df['clean_tweet'] = df[text_column].apply(lambda x: re.sub(r'http\\S+|www.\\S+|mailto:\\S+', '', x))\n",
    "    \n",
    "    # Uklanjanje HTML tagova\n",
    "    df['clean_tweet'] = df['clean_tweet'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
    "    \n",
    "    # Uklanjanje emotikona i specijalnih karaktera\n",
    "    def remove_emojis(text):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emotikoni\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # simobli i ikone\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport i simobli\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # zastave\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "\n",
    "    df['clean_tweet'] = df['clean_tweet'].apply(remove_emojis)\n",
    "    \n",
    "    # Uklanjanje specijalnih karaktera i interpunkcije\n",
    "    df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(r'[^A-Za-zšđčćžŠĐČĆŽ ]+', ' ', x))\n",
    "    \n",
    "    # Pretvaranje u mala slova\n",
    "    df['clean_tweet'] = df['clean_tweet'].str.lower()\n",
    "    \n",
    "    # Uklanjanje dijakritika\n",
    "    def remove_diacritics(text):\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        text = ''.join([c for c in text if not unicodedata.combining(c)])\n",
    "        return text\n",
    "\n",
    "    df['clean_tweet'] = df['clean_tweet'].apply(remove_diacritics)\n",
    "    \n",
    "    # Uklanjanje višestrukih razmaka\n",
    "    df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub('\\s+', ' ', x).strip())\n",
    "    \n",
    "    # Tokenizacija\n",
    "    df['tokens'] = df['clean_tweet'].apply(nltk.word_tokenize)\n",
    "    \n",
    "    # Uklanjanje stop-reči\n",
    "    stop_words = set(stopwords.words('english'))  # Ako imaš stop-reči za srpski, zameni ovde\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    # Lematizacija\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    \n",
    "    # Spajanje tokena nazad u string\n",
    "    df['clean_tweet'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # Uklanjanje nepotrebnih kolona\n",
    "    df = df.drop(columns=['tokens'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaca\\AppData\\Local\\Temp\\ipykernel_21012\\2996977020.py:19: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df['clean_tweet'] = df['clean_tweet'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   tweet  label  \\\n",
      "0      !!! RT @mayasolovely: As a woman you shouldn't...      0   \n",
      "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1   \n",
      "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1   \n",
      "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1   \n",
      "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1   \n",
      "...                                                  ...    ...   \n",
      "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...      1   \n",
      "24779  you've gone and broke the wrong heart baby, an...      0   \n",
      "24780  young buck wanna eat!!.. dat nigguh like I ain...      1   \n",
      "24781              youu got wild bitches tellin you lies      1   \n",
      "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...      0   \n",
      "\n",
      "                                             clean_tweet  \n",
      "0      rt mayasolovely woman complain cleaning house ...  \n",
      "1      rt mleew boy dat cold tyga dwn bad cuffin dat ...  \n",
      "2      rt urkindofbrand dawg rt sbaby life ever fuck ...  \n",
      "3            rt c g anderson viva based look like tranny  \n",
      "4      rt shenikaroberts shit hear might true might f...  \n",
      "...                                                  ...  \n",
      "24778  muthaf lie lifeasking pearl corey emanuel righ...  \n",
      "24779    gone broke wrong heart baby drove redneck crazy  \n",
      "24780  young buck wan na eat dat nigguh like aint fuc...  \n",
      "24781                     youu got wild bitch tellin lie  \n",
      "24782  ruffled ntac eileen dahlia beautiful color com...  \n",
      "\n",
      "[24783 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_text(df, 'tweet')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definisanje metoda mašinskog učenja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Logistička regresija:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "def train_svm(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"SVM:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "def train_naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Naivni Bajes:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definisanje neuronskih mreža"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "def prepare_tokenizer(texts, num_words=5000):\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer\n",
    "\n",
    "def tokenize_and_pad(tokenizer, texts, maxlen=100):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=maxlen)\n",
    "    return padded\n",
    "\n",
    "def train_lstm(X_train, y_train, X_test, y_test, vocab_size, maxlen=100):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=maxlen))\n",
    "    model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=64)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'LSTM Test Accuracy: {accuracy}')\n",
    "    return model\n",
    "\n",
    "def train_cnn(X_train, y_train, X_test, y_test, vocab_size, maxlen=100):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=maxlen))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=64)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'CNN Test Accuracy: {accuracy}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definisanje BERT modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1149\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     31\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     39\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertForSequenceClassification\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_bert\u001b[39m(X_train, y_train, X_test, y_test, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-multilingual-cased\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1231\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1594\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1591\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1605\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1608\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "def train_bert(X_train, y_train, X_test, y_test, model_name='bert-base-multilingual-cased', epochs=3):\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Tokenizacija i enkodiranje\n",
    "    def encode_texts(texts):\n",
    "        return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "    \n",
    "    train_encodings = encode_texts(X_train)\n",
    "    test_encodings = encode_texts(X_test)\n",
    "    \n",
    "    # Konvertovanje labela u tensor\n",
    "    y_train = tf.convert_to_tensor(y_train)\n",
    "    y_test = tf.convert_to_tensor(y_test)\n",
    "    \n",
    "    # Kreiranje TensorFlow dataset-a\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test))\n",
    "    \n",
    "    # Batchevi\n",
    "    train_dataset = train_dataset.shuffle(len(X_train)).batch(8)\n",
    "    test_dataset = test_dataset.batch(8)\n",
    "    \n",
    "    # Model\n",
    "    model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    \n",
    "    # Kompajliranje modela\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "    model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Treniranje modela\n",
    "    model.fit(train_dataset, validation_data=test_dataset, epochs=epochs)\n",
    "    \n",
    "    # Evaluacija\n",
    "    loss, accuracy = model.evaluate(test_dataset)\n",
    "    print(f'BERT Test Accuracy: {accuracy}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_type='sklearn', tokenizer=None, maxlen=100):\n",
    "    \"\"\"\n",
    "    Evaluira model i prikazuje metrike performansi.\n",
    "    \n",
    "    Argumenti:\n",
    "    - model: istrenirani model\n",
    "    - X_test: test podaci (tekstualni ili vektorski)\n",
    "    - y_test: stvarne labela\n",
    "    - model_type: 'sklearn', 'keras', ili 'bert'\n",
    "    - tokenizer: Tokenizer objekat (potreban za neuronske mreže)\n",
    "    - maxlen: maksimalna dužina sekvenci (za neuronske mreže)\n",
    "    \"\"\"\n",
    "    if model_type == 'sklearn':\n",
    "        y_pred = model.predict(X_test)\n",
    "    elif model_type == 'keras':\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    elif model_type == 'bert':\n",
    "        y_pred = model.predict(X_test).logits\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Nepoznat tip modela.\")\n",
    "    \n",
    "    print(\"Izveštaj o klasifikaciji:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Matrica konfuzije:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primena algoritama nad originalnim podacima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['clean_tweet']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4.4. Vektorizacija za klasične modele\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 4.7. Tokenizacija za neuronske mreže\n",
    "tokenizer = prepare_tokenizer(X_train, num_words=5000)\n",
    "X_train_seq = tokenize_and_pad(tokenizer, X_train)\n",
    "X_test_seq = tokenize_and_pad(tokenizer, X_test)\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 za rezervisani indeks 0\n",
    "\n",
    "# 4.12. Treniranje BERT modela\n",
    "# bert_model = train_bert(X_train.tolist(), y_train.tolist(), X_test.tolist(), y_test.tolist(), model_name='distilbert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistička regresija:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1125\n",
      "           1       0.92      0.95      0.93      3832\n",
      "\n",
      "    accuracy                           0.90      4957\n",
      "   macro avg       0.86      0.83      0.85      4957\n",
      "weighted avg       0.89      0.90      0.89      4957\n",
      "\n",
      "Izveštaj o klasifikaciji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1125\n",
      "           1       0.92      0.95      0.93      3832\n",
      "\n",
      "    accuracy                           0.90      4957\n",
      "   macro avg       0.86      0.83      0.85      4957\n",
      "weighted avg       0.89      0.90      0.89      4957\n",
      "\n",
      "Matrica konfuzije:\n",
      "[[ 811  314]\n",
      " [ 197 3635]]\n"
     ]
    }
   ],
   "source": [
    "lr_model = train_logistic_regression(X_train_vec, y_train, X_test_vec, y_test)\n",
    "evaluate_model(lr_model, X_test_vec, y_test, model_type='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78      1125\n",
      "           1       0.93      0.95      0.94      3832\n",
      "\n",
      "    accuracy                           0.90      4957\n",
      "   macro avg       0.87      0.85      0.86      4957\n",
      "weighted avg       0.90      0.90      0.90      4957\n",
      "\n",
      "Izveštaj o klasifikaciji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78      1125\n",
      "           1       0.93      0.95      0.94      3832\n",
      "\n",
      "    accuracy                           0.90      4957\n",
      "   macro avg       0.87      0.85      0.86      4957\n",
      "weighted avg       0.90      0.90      0.90      4957\n",
      "\n",
      "Matrica konfuzije:\n",
      "[[ 845  280]\n",
      " [ 205 3627]]\n"
     ]
    }
   ],
   "source": [
    "svm_model = train_svm(X_train_vec, y_train, X_test_vec, y_test)\n",
    "evaluate_model(svm_model, X_test_vec, y_test, model_type='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naivni Bajes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.37      0.52      1125\n",
      "           1       0.84      0.98      0.91      3832\n",
      "\n",
      "    accuracy                           0.84      4957\n",
      "   macro avg       0.86      0.68      0.71      4957\n",
      "weighted avg       0.85      0.84      0.82      4957\n",
      "\n",
      "Izveštaj o klasifikaciji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.37      0.52      1125\n",
      "           1       0.84      0.98      0.91      3832\n",
      "\n",
      "    accuracy                           0.84      4957\n",
      "   macro avg       0.86      0.68      0.71      4957\n",
      "weighted avg       0.85      0.84      0.82      4957\n",
      "\n",
      "Matrica konfuzije:\n",
      "[[ 415  710]\n",
      " [  62 3770]]\n"
     ]
    }
   ],
   "source": [
    "nb_model = train_naive_bayes(X_train_vec, y_train, X_test_vec, y_test)\n",
    "evaluate_model(nb_model, X_test_vec, y_test, model_type='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 187ms/step - accuracy: 0.8275 - loss: 0.3923 - val_accuracy: 0.9072 - val_loss: 0.2442\n",
      "Epoch 2/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 197ms/step - accuracy: 0.9243 - loss: 0.2144 - val_accuracy: 0.9046 - val_loss: 0.2609\n",
      "Epoch 3/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 214ms/step - accuracy: 0.9425 - loss: 0.1712 - val_accuracy: 0.8997 - val_loss: 0.2638\n",
      "Epoch 4/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 231ms/step - accuracy: 0.9505 - loss: 0.1499 - val_accuracy: 0.9001 - val_loss: 0.2845\n",
      "Epoch 5/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 241ms/step - accuracy: 0.9550 - loss: 0.1243 - val_accuracy: 0.8921 - val_loss: 0.3321\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.8957 - loss: 0.3286\n",
      "LSTM Test Accuracy: 0.8920718431472778\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step\n",
      "Izveštaj o klasifikaciji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74      1125\n",
      "           1       0.91      0.95      0.93      3832\n",
      "\n",
      "    accuracy                           0.89      4957\n",
      "   macro avg       0.86      0.82      0.84      4957\n",
      "weighted avg       0.89      0.89      0.89      4957\n",
      "\n",
      "Matrica konfuzije:\n",
      "[[ 780  345]\n",
      " [ 190 3642]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model = train_lstm(X_train_seq, y_train, X_test_seq, y_test, vocab_size)\n",
    "evaluate_model(lstm_model, X_test_seq, y_test, model_type='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - accuracy: 0.8415 - loss: 0.3849 - val_accuracy: 0.9030 - val_loss: 0.2517\n",
      "Epoch 2/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 91ms/step - accuracy: 0.9273 - loss: 0.2064 - val_accuracy: 0.8951 - val_loss: 0.2613\n",
      "Epoch 3/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - accuracy: 0.9492 - loss: 0.1493 - val_accuracy: 0.8884 - val_loss: 0.3304\n",
      "Epoch 4/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - accuracy: 0.9725 - loss: 0.0869 - val_accuracy: 0.8765 - val_loss: 0.4004\n",
      "Epoch 5/5\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.9848 - loss: 0.0486 - val_accuracy: 0.8703 - val_loss: 0.5020\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8672 - loss: 0.4951\n",
      "CNN Test Accuracy: 0.8702844381332397\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "Izveštaj o klasifikaciji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70      1125\n",
      "           1       0.90      0.93      0.92      3832\n",
      "\n",
      "    accuracy                           0.87      4957\n",
      "   macro avg       0.82      0.79      0.81      4957\n",
      "weighted avg       0.87      0.87      0.87      4957\n",
      "\n",
      "Matrica konfuzije:\n",
      "[[ 738  387]\n",
      " [ 256 3576]]\n"
     ]
    }
   ],
   "source": [
    "cnn_model = train_cnn(X_train_seq, y_train, X_test_seq, y_test, vocab_size)\n",
    "evaluate_model(cnn_model, X_test_seq, y_test, model_type='keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentacija podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definisanje metoda za prve dve kombinacije\n",
    "# # methods_set1 = [synonym_replacement, random_insertion, back_translation_cached]\n",
    "# # methods_set2 = [simulate_typos, back_translation, bert_augmentation]\n",
    "\n",
    "# # OVO RADI\n",
    "# # FUNKCIJE KOJE KORISTE LOCKING GA BLOKIRAJU\n",
    "# # Ciljani broj instanci u negativnoj klasi (balansiranje)\n",
    "# positive_count = data[data['label'] == 1].shape[0]\n",
    "# print(f\"Broj pozitivnih instanci (label=1): {positive_count}\")\n",
    "\n",
    "# # Treniranje augmentacije na set1\n",
    "# print(\"\\nAugmentacija - Set 1:\")\n",
    "# df_augmented_set1_parallel = augment_negative_class_parallel(\n",
    "#     data, \n",
    "#     text_column='clean_tweet', \n",
    "#     label_column='label', \n",
    "#     methods=[back_translation_cached, random_character_swap], \n",
    "#     target_count=positive_count, \n",
    "#     max_workers=8  # Podesi broj radnika prema dostupnim resursima\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importovanje potrebnih biblioteka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from googletrans import Translator\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Preuzimanje potrebnih NLTK resursa\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definisanje metoda augmentacije podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metode augmentacije na nivou karaktera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_spelling_errors(text, error_prob=0.1):\n",
    "    \"\"\"\n",
    "    Simulira pravopisne greške u tekstu.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - error_prob: Verovatnoća da će svaki karakter biti izmenjen.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa simuliranim pravopisnim greškama.\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    result = ''\n",
    "    for c in text:\n",
    "        if c.lower() in letters and random.random() < error_prob:\n",
    "            result += random.choice(letters)\n",
    "        else:\n",
    "            result += c\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyboard_augmenter(text, error_prob=0.1):\n",
    "    \"\"\"\n",
    "    Simulira greške u kucanju na osnovu rasporeda tastature.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - error_prob: Verovatnoća da će svaki karakter biti zamenjen.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa simuliranim greškama u kucanju.\n",
    "    \"\"\"\n",
    "    keyboard_neighbors = {\n",
    "        'a': 'qwsz',\n",
    "        'b': 'vghn',\n",
    "        'c': 'xdfv',\n",
    "        'd': 'ersfcx',\n",
    "        'e': 'wsdfr',\n",
    "        'f': 'rtgdvc',\n",
    "        'g': 'tyfhvb',\n",
    "        'h': 'yugjbn',\n",
    "        'i': 'ujklo',\n",
    "        'j': 'uikhmn',\n",
    "        'k': 'ijolm,',\n",
    "        'l': 'kop;.',\n",
    "        'm': 'njk,',\n",
    "        'n': 'bhjm',\n",
    "        'o': 'iklp',\n",
    "        'p': 'ol;',\n",
    "        'q': 'wa',\n",
    "        'r': 'edft',\n",
    "        's': 'wedxz',\n",
    "        't': 'rfgy',\n",
    "        'u': 'yhji',\n",
    "        'v': 'cfgb',\n",
    "        'w': 'qase',\n",
    "        'x': 'zsdc',\n",
    "        'y': 'tghu',\n",
    "        'z': 'asx'\n",
    "    }\n",
    "    result = ''\n",
    "    for c in text:\n",
    "        lower_c = c.lower()\n",
    "        if lower_c in keyboard_neighbors and random.random() < error_prob:\n",
    "            result += random.choice(keyboard_neighbors[lower_c])\n",
    "        else:\n",
    "            result += c\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_simulation(text, error_prob=0.05):\n",
    "    \"\"\"\n",
    "    Simulira OCR greške u tekstu.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - error_prob: Verovatnoća da će svaki karakter biti zamenjen.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa simuliranim OCR greškama.\n",
    "    \"\"\"\n",
    "    ocr_errors = {\n",
    "        '0': ['O', 'o'],\n",
    "        '1': ['I', 'l'],\n",
    "        'l': ['1', 'I'],\n",
    "        'O': ['0', 'o'],\n",
    "        'o': ['0', 'O'],\n",
    "        'I': ['1', 'l']\n",
    "    }\n",
    "    result = ''\n",
    "    for c in text:\n",
    "        if c in ocr_errors and random.random() < error_prob:\n",
    "            result += random.choice(ocr_errors[c])\n",
    "        else:\n",
    "            result += c\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_character_augmentation(text, aug_prob=0.1):\n",
    "    \"\"\"\n",
    "    Nasumična augmentacija karaktera u tekstu.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - aug_prob: Verovatnoća da će svaka operacija biti primenjena na karakter.\n",
    "    \n",
    "    Vraća:\n",
    "    - Augmentirani tekst.\n",
    "    \"\"\"\n",
    "    functions = [delete_random_char, substitute_random_char, swap_random_chars, insert_random_char]\n",
    "    augmented_text = text\n",
    "    for func in functions:\n",
    "        augmented_text = func(augmented_text, aug_prob)\n",
    "    return augmented_text\n",
    "\n",
    "def delete_random_char(text, aug_prob):\n",
    "    result = ''\n",
    "    for c in text:\n",
    "        if random.random() > aug_prob:\n",
    "            result += c\n",
    "    return result\n",
    "\n",
    "def substitute_random_char(text, aug_prob):\n",
    "    letters = string.ascii_letters\n",
    "    result = ''\n",
    "    for c in text:\n",
    "        if random.random() < aug_prob:\n",
    "            result += random.choice(letters)\n",
    "        else:\n",
    "            result += c\n",
    "    return result\n",
    "\n",
    "def swap_random_chars(text, aug_prob):\n",
    "    text = list(text)\n",
    "    for i in range(len(text)-1):\n",
    "        if random.random() < aug_prob:\n",
    "            text[i], text[i+1] = text[i+1], text[i]\n",
    "    return ''.join(text)\n",
    "\n",
    "def insert_random_char(text, aug_prob):\n",
    "    result = ''\n",
    "    letters = string.ascii_letters\n",
    "    for c in text:\n",
    "        result += c\n",
    "        if random.random() < aug_prob:\n",
    "            result += random.choice(letters)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metode augmentacije na nivou reči"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(text, n=2):\n",
    "    \"\"\"\n",
    "    Zamenjuje n reči njihovim sinonimima.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - n: Broj reči koje će biti zamenjene.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa zamenjenim sinonimima.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set(words))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    augmented_text = ' '.join(new_words)\n",
    "    return augmented_text\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lem in syn.lemmas():\n",
    "            synonym = lem.name().replace('_', ' ').lower()\n",
    "            if synonym != word:\n",
    "                synonyms.add(synonym)\n",
    "    return list(synonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antonym_replacement(text, n=2):\n",
    "    \"\"\"\n",
    "    Zamenjuje n reči njihovim antonimima.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - n: Broj reči koje će biti zamenjene.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa zamenjenim antonimima.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set(words))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        antonyms = get_antonyms(random_word)\n",
    "        if len(antonyms) >= 1:\n",
    "            antonym = random.choice(antonyms)\n",
    "            new_words = [antonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    augmented_text = ' '.join(new_words)\n",
    "    return augmented_text\n",
    "\n",
    "def get_antonyms(word):\n",
    "    antonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lem in syn.lemmas():\n",
    "            for ant in lem.antonyms():\n",
    "                antonym = ant.name().replace('_', ' ').lower()\n",
    "                antonyms.add(antonym)\n",
    "    return list(antonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_insertion(text, n=2):\n",
    "    \"\"\"\n",
    "    Umeće n sinonima nasumično u tekst.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - n: Broj reči koje će biti umetnute.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa umetnutim rečima.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    for _ in range(n):\n",
    "        add_word(words)\n",
    "    augmented_text = ' '.join(words)\n",
    "    return augmented_text\n",
    "\n",
    "def add_word(words):\n",
    "    synonyms = []\n",
    "    counter = 0\n",
    "    while len(synonyms) < 1 and counter < 10:\n",
    "        random_word = words[random.randint(0, len(words)-1)]\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        counter += 1\n",
    "    if len(synonyms) >= 1:\n",
    "        synonym = random.choice(synonyms)\n",
    "        random_idx = random.randint(0, len(words))\n",
    "        words.insert(random_idx, synonym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(text, n=2):\n",
    "    \"\"\"\n",
    "    Menja mesta dvema rečima u tekstu n puta.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - n: Broj zamena.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa zamenjenim rečima.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    for _ in range(n):\n",
    "        words = swap_word(words)\n",
    "    augmented_text = ' '.join(words)\n",
    "    return augmented_text\n",
    "\n",
    "def swap_word(words):\n",
    "    idx1 = random.randint(0, len(words)-1)\n",
    "    idx2 = random.randint(0, len(words)-1)\n",
    "    words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(text, p=0.2):\n",
    "    \"\"\"\n",
    "    Briše reči iz teksta sa verovatnoćom p.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - p: Verovatnoća brisanja reči.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa obrisanim rečima.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) == 1:\n",
    "        return text\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if random.uniform(0,1) > p:\n",
    "            new_words.append(word)\n",
    "    if len(new_words) == 0:\n",
    "        return random.choice(words)\n",
    "    else:\n",
    "        return ' '.join(new_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_augmentation(text, n=2):\n",
    "    \"\"\"\n",
    "    Deli n reči na manje delove.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - n: Broj reči koje će biti podeljene.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa podeljenim rečima.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    num_splits = 0\n",
    "    while num_splits < n:\n",
    "        idx = random.randint(0, len(new_words)-1)\n",
    "        word = new_words[idx]\n",
    "        if len(word) > 1:\n",
    "            split_point = random.randint(1, len(word)-1)\n",
    "            new_words[idx:idx+1] = [word[:split_point], word[split_point:]]\n",
    "            num_splits += 1\n",
    "        if num_splits >= n:\n",
    "            break\n",
    "    return ' '.join(new_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_augmentation(text, error_prob=0.1):\n",
    "    \"\"\"\n",
    "    Umeće pravopisne greške u reči.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - error_prob: Verovatnoća da će reč biti izmenjena.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa pravopisnim greškama.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if random.random() < error_prob:\n",
    "            new_word = random_character_augmentation(word, aug_prob=0.2)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Učitajte pretrenirane rečničke vektore (npr. GloVe ili Word2Vec)\n",
    "# Ovaj primer koristi Google pretrenirani Word2Vec model (mora biti preuzet)\n",
    "# word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "def embedding_replacement(text, n=2, word_vectors=None):\n",
    "    \"\"\"\n",
    "    Zamenjuje reči sličnim rečima na osnovu embeddinga.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - n: Broj reči koje će biti zamenjene.\n",
    "    - word_vectors: Pretrenirani model rečničkih vektora.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa zamenjenim rečima.\n",
    "    \"\"\"\n",
    "    if word_vectors is None:\n",
    "        raise ValueError(\"word_vectors model must be provided\")\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set(words))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for word in random_word_list:\n",
    "        if word in word_vectors:\n",
    "            similar_words = [w for w, sim in word_vectors.most_similar(word)]\n",
    "            if similar_words:\n",
    "                similar_word = random.choice(similar_words)\n",
    "                new_words = [similar_word if w == word else w for w in new_words]\n",
    "                num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "    return ' '.join(new_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_embedding_augmentation(text, mask_token='[MASK]', top_k=5):\n",
    "    \"\"\"\n",
    "    Zamenjuje reči koristeći kontekstualne modele (npr. BERT).\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - mask_token: Token koji se koristi za maskiranje (default: '[MASK]').\n",
    "    - top_k: Broj najboljih predikcija za izbor.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa zamenjenim rečima.\n",
    "    \"\"\"\n",
    "    unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "    words = text.split()\n",
    "    num_masks = max(1, int(0.15 * len(words)))\n",
    "    masked_indices = random.sample(range(len(words)), num_masks)\n",
    "    for idx in masked_indices:\n",
    "        original_word = words[idx]\n",
    "        words[idx] = mask_token\n",
    "        masked_text = ' '.join(words)\n",
    "        predictions = unmasker(masked_text)\n",
    "        for pred in predictions[:top_k]:\n",
    "            new_word = pred['token_str']\n",
    "            if new_word != original_word:\n",
    "                words[idx] = new_word\n",
    "                break\n",
    "        else:\n",
    "            words[idx] = original_word\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metode augmentacije na nivu fraza i rečenica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_text(text, model=None, tokenizer=None, device='cpu'):\n",
    "    \"\"\"\n",
    "    Parafrazira tekst koristeći T5 model.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - model: Pretrenirani T5 model.\n",
    "    - tokenizer: T5 tokenizer.\n",
    "    - device: 'cpu' ili 'cuda'.\n",
    "    \n",
    "    Vraća:\n",
    "    - Parafrazirani tekst.\n",
    "    \"\"\"\n",
    "    if model is None or tokenizer is None:\n",
    "        model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "        tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "        model = model.to(device)\n",
    "    input_text = \"paraphrase: \" + text + \" </s>\"\n",
    "    encoding = tokenizer.encode_plus(input_text, padding='longest', return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "        top_k=120,\n",
    "        top_p=0.95,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    paraphrased_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return paraphrased_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translation(text, src_language='en', target_language='de'):\n",
    "    \"\"\"\n",
    "    Back-Translation metode.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    - src_language: Izvorni jezik.\n",
    "    - target_language: Ciljni jezik za prevođenje.\n",
    "    \n",
    "    Vraća:\n",
    "    - Back-translated tekst.\n",
    "    \"\"\"\n",
    "    translator = Translator()\n",
    "    translated = translator.translate(text, src=src_language, dest=target_language).text\n",
    "    back_translated = translator.translate(translated, src=target_language, dest=src_language).text\n",
    "    return back_translated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sentence_augmentation(text):\n",
    "    \"\"\"\n",
    "    Nasumično menja redosled rečenica u tekstu.\n",
    "    \n",
    "    Argumenti:\n",
    "    - text: Originalni tekst.\n",
    "    \n",
    "    Vraća:\n",
    "    - Tekst sa promenjenim redosledom rečenica.\n",
    "    \"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    random.shuffle(sentences)\n",
    "    return ' '.join(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_gpt2(prompt, max_length=50):\n",
    "    \"\"\"\n",
    "    Generiše tekst koristeći GPT-2 model.\n",
    "    \n",
    "    Argumenti:\n",
    "    - prompt: Početni tekst.\n",
    "    - max_length: Maksimalna dužina generisanog teksta.\n",
    "    \n",
    "    Vraća:\n",
    "    - Generisani tekst.\n",
    "    \"\"\"\n",
    "    generator = pipeline('text-generation', model='gpt2')\n",
    "    outputs = generator(prompt, max_length=max_length, num_return_sequences=1)\n",
    "    return outputs[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primena metoda nad augmentiranim podacima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(df, text_column, method, num_augmented_instances, **kwargs):\n",
    "    \"\"\"\n",
    "    Primeni izabranu metodu augmentacije na dataset.\n",
    "    \n",
    "    Argumenti:\n",
    "    - df: Originalni DataFrame.\n",
    "    - text_column: Naziv kolone sa tekstom.\n",
    "    - method: Funkcija metode augmentacije.\n",
    "    - num_augmented_instances: Broj instanci koje treba generisati.\n",
    "    - **kwargs: Dodatni argumenti za metodu augmentacije.\n",
    "    \n",
    "    Vraća:\n",
    "    - DataFrame sa augmentiranim podacima.\n",
    "    \"\"\"\n",
    "    augmented_texts = []\n",
    "    indices = df.index.tolist()\n",
    "    num_samples = len(indices)\n",
    "    \n",
    "    # Ako je broj instanci veći od broja dostupnih uzoraka, uzmi uzorke sa zamjenom\n",
    "    replace = num_augmented_instances > num_samples\n",
    "    sampled_indices = np.random.choice(indices, size=num_augmented_instances, replace=replace)\n",
    "    \n",
    "    for idx in tqdm(sampled_indices, desc=f'Augmenting with {method.__name__}'):\n",
    "        original_text = df.loc[idx, text_column]\n",
    "        augmented_text = method(original_text, **kwargs)\n",
    "        augmented_texts.append(augmented_text)\n",
    "    \n",
    "    augmented_df = pd.DataFrame({text_column: augmented_texts})\n",
    "    return augmented_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiši broj instanci koje želiš da generišeš\n",
    "num_instances = 20\n",
    "methods = [simulate_spelling_errors, keyboard_augmenter, ocr_simulation, random_character_augmentation, synonym_replacement, antonym_replacement, random_insertion, random_swap, random_deletion, split_augmentation, spelling_augmentation, back_translation, random_sentence_augmentation]\n",
    "\n",
    "augmented_df_synonyms = augment_dataset(\n",
    "    data, \n",
    "    text_column='clean_tweet', \n",
    "    method=synonym_replacement, \n",
    "    num_augmented_instances=num_instances, \n",
    "    n=2  # Broj reči koje će biti zamenjene\n",
    ")\n",
    "\n",
    "# for method in methods:\n",
    "#     augmented_df = augment_dataset(\n",
    "#     data, \n",
    "#     text_column='clean_tweet', \n",
    "#     method=method, \n",
    "#     num_augmented_instances=num_instances\n",
    "#             )\n",
    "#     print(\"Method: \", method)\n",
    "#     print(augmented_df, '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented_set1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predobrada nije potrebna jer smo već očistili tekst\n",
    "\n",
    "# Podela na trening i test skup\n",
    "X_aug1 = df_augmented_set1['clean_tweet']\n",
    "y_aug1 = df_augmented_set1['label']\n",
    "\n",
    "X_train_aug1, X_test_aug1, y_train_aug1, y_test_aug1 = train_test_split(X_aug1, y_aug1, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_aug1 = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec_aug1 = vectorizer_aug1.fit_transform(X_train_aug1)\n",
    "X_test_vec_aug1 = vectorizer_aug1.transform(X_test_aug1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistička regresija\n",
    "lr_model_aug1 = train_logistic_regression(X_train_vec_aug1, y_train_aug1, X_test_vec_aug1, y_test_aug1)\n",
    "\n",
    "# SVM\n",
    "svm_model_aug1 = train_svm(X_train_vec_aug1, y_train_aug1, X_test_vec_aug1, y_test_aug1)\n",
    "\n",
    "# Naivni Bajes\n",
    "nb_model_aug1 = train_naive_bayes(X_train_vec_aug1, y_train_aug1, X_test_vec_aug1, y_test_aug1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizacija\n",
    "tokenizer_aug1 = prepare_tokenizer(X_train_aug1, num_words=5000)\n",
    "X_train_seq_aug1 = tokenize_and_pad(tokenizer_aug1, X_train_aug1)\n",
    "X_test_seq_aug1 = tokenize_and_pad(tokenizer_aug1, X_test_aug1)\n",
    "vocab_size_aug1 = len(tokenizer_aug1.word_index) + 1\n",
    "\n",
    "# LSTM\n",
    "lstm_model_aug1 = train_lstm(X_train_seq_aug1, y_train_aug1, X_test_seq_aug1, y_test_aug1, vocab_size_aug1)\n",
    "\n",
    "# CNN\n",
    "cnn_model_aug1 = train_cnn(X_train_seq_aug1, y_train_aug1, X_test_seq_aug1, y_test_aug1, vocab_size_aug1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
